{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Trial_3_Unsuccessful_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!echo '{\"username\":\"YOUR-USERNAME\",\"key\":\"YOUR-API-KEY\"}' > ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "c49pL7d0Jqka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2IO_AuKHek0",
        "outputId": "670f5ff7-5905-43f1-a9d4-624fc35dca22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fraud-detection.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d kartik2112/fraud-detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o fraud-detection.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX7QN1TRSbup",
        "outputId": "88219bd2-d4b3-4073-e855-ec191ff34c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  fraud-detection.zip\n",
            "  inflating: fraudTest.csv           \n",
            "  inflating: fraudTrain.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "4U5-c1LoSgR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('fraudTrain.csv', index_col=0)\n",
        "y = df['is_fraud']"
      ],
      "metadata": {
        "id": "4Z9ks0MPSoDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Source: https://stackoverflow.com/a/29546836/6948907\n",
        "\n",
        "def haversine_np(lon1, lat1, lon2, lat2):\n",
        "    \"\"\"\n",
        "    Calculate the great circle distance between two points\n",
        "    on the earth (specified in decimal degrees)\n",
        "    All args must be of equal length.    \n",
        "\n",
        "    \"\"\"\n",
        "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
        "\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
        "\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    km = 6367 * c\n",
        "    return km\n",
        "\n",
        "def is_weekend(txn_time):\n",
        "    return int(txn_time.weekday() >= 5)\n",
        "\n",
        "def is_night(txn_time):\n",
        "    return int(txn_time.hour <= 6 or txn_time.hour >= 22)"
      ],
      "metadata": {
        "id": "fmMYwqe434ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_txn_history(txns, windows=[7, 15, 30, 60]):\n",
        "    txns = txns.sort_values('trans_date_trans_time')\n",
        "    txns.index = txns.trans_date_trans_time\n",
        "    \n",
        "    for window in windows:\n",
        "        total_amt = txns['amt'].rolling(window, min_periods = 1).sum()\n",
        "        count_amt = txns['amt'].rolling(window, min_periods = 1).count()\n",
        "\n",
        "        avg_amt = total_amt/count_amt\n",
        "\n",
        "        txns[f'count_amt_{window}_days'] = list(count_amt)\n",
        "        txns[f'count_avg_{window}_days'] = list(avg_amt)\n",
        "\n",
        "    txns.reset_index(drop = True)\n",
        "    return txns"
      ],
      "metadata": {
        "id": "RukxYgiiGNz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_columns(df):\n",
        "    \n",
        "    df=df.groupby('cc_num').apply(lambda x: get_txn_history(x, windows_size_in_days=[1,7,15,30]))\n",
        "    df.reset_index(drop=True, inplace = True)\n",
        "    df=df.sort_values('trans_date_trans_time')\n",
        "    df['distance_bet_user_merchant'] = haversine_np(df['lat'],df['long'],df['merch_lat'],df['merch_long'])\n",
        "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
        "    df['dob'] = pd.to_datetime(df['dob'])\n",
        "    df['user_age'] = (df['trans_date_trans_time'] - df['dob']).astype('<m8[Y]').apply(pd.to_numeric)\n",
        "    df['txn_at_night'] = df['trans_date_trans_time'].apply(lambda txn_time: is_night(txn_time))\n",
        "    df['txn_on_weekend'] = df['trans_date_trans_time'].apply(lambda txn_time: is_weekend(txn_time))\n",
        "    df.drop(axis = 1, inplace = True, columns = [ 'trans_num', 'street', 'first', 'last', 'gender', 'unix_time', 'city', 'state',\n",
        "                'trans_date_trans_time', 'dob', 'job', 'cc_num', 'is_fraud', 'category', 'merchant'])\n",
        "    return df"
      ],
      "metadata": {
        "id": "JjP2MknU4GO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('transform_columns', FunctionTransformer(func=transform_columns), ['cc_num', 'trans_date_trans_time', 'lat', \n",
        "                                                                            'long','merch_lat', 'merch_long', 'dob', \n",
        "                                                                            'amt',  'trans_num', 'street', 'first', \n",
        "                                                                            'last', 'gender', 'unix_time', 'city', 'state',\n",
        "                                                                            'job', 'is_fraud', 'category', 'merchant']),\n",
        "        \n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "djVNLaYp2TC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "\n",
        "class CategoryEncoder(BaseEstimator):\n",
        "    def __init__(self):\n",
        "        self.cat_ohe = OneHotEncoder(handle_unknown='ignore')\n",
        "        self.merchant_oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "        self.city_oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "        self.state_oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "        self.job_oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "\n",
        "    def fit(self, df, y=None):\n",
        "        self.cat_ohe.fit(df[\"category\"].values.reshape(-1, 1))\n",
        "        df['merchant'] = df['merchant'].apply(lambda name : name.replace(\"fraud_\", \"\"))\n",
        "        self.merchant_oe.fit(df[\"merchant\"].values.reshape(-1, 1))\n",
        "        self.city_oe.fit(df[\"city\"].values.reshape(-1, 1))\n",
        "        self.state_oe.fit(df[\"state\"].values.reshape(-1, 1))\n",
        "        self.job_oe.fit(df[\"job\"].values.reshape(-1, 1))\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        ohe_df = pd.DataFrame(self.cat_ohe.transform(df['category'].values.reshape(-1, 1)).toarray())\n",
        "        df = df.join(ohe_df)\n",
        "\n",
        "        df['merchant'] = df['merchant'].apply(lambda name : name.replace(\"fraud_\", \"\"))\n",
        "        df['merchant_oe'] = self.merchant_oe.transform(df['merchant'].values.reshape(-1, 1)).ravel()\n",
        "\n",
        "        df['city_oe'] = self.city_oe.transform(df['city'].values.reshape(-1, 1)).ravel()\n",
        "        df['state_oe'] = self.state_oe.transform(df['state'].values.reshape(-1, 1)).ravel()\n",
        "        df['job_oe'] = self.job_oe.transform(df['job'].values.reshape(-1, 1)).ravel()\n",
        "        # print(df.columns)\n",
        "        return df"
      ],
      "metadata": {
        "id": "a7C7-6Ll6XU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "MAX_ITER = 500\n",
        "CLASS_WEIGHTS = {\n",
        "    0: 1,\n",
        "    1: 90,\n",
        "}\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    steps = [\n",
        "        ('categorical_encoding', CategoryEncoder()),\n",
        "        ('pre_processing', preprocessor),\n",
        "        ('scaling', StandardScaler()),\n",
        "        # ('debug', Debug()), \n",
        "        ('logistic_regression', SVC(max_iter=1000))\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "V5yn34x45-CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "pipeline.fit(df, y)\n",
        "pipeline.score(df, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVEW15879OGa",
        "outputId": "871c0038-dc66-4d8f-833e-48707830d5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9899535350029884"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y, pipeline.predict(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLSQ1DJskYiy",
        "outputId": "14f6ce44-0458-4dc5-a610-cddc993b7f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1283176,    5993],\n",
              "       [   7034,     472]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('fraudTest.csv', index_col=0)\n",
        "test_y = test_df['is_fraud']\n",
        "print(pipeline.score(test_df, test_y))\n",
        "confusion_matrix(test_y, pipeline.predict(test_df))"
      ],
      "metadata": {
        "id": "EEwNFF6gEZ4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2365be07-fe20-4466-8c76-61a099c4a7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9914273220818435\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[550820,   2754],\n",
              "       [  2010,    135]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(pipeline.predict(test_df), test_y))"
      ],
      "metadata": {
        "id": "syREvclzN-_n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}